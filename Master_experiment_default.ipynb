{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "opj = os.path.join\n",
    "\n",
    "import ccxt \n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd \n",
    "from pytorch_tabnet.tab_model import TabNetClassifier, TabNetRegressor \n",
    "from sklearn.metrics import f1_score, mean_squared_error, mean_absolute_error\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dir = \".\"\n",
    "df_files = [\n",
    "    \"default.csv\",\n",
    "]\n",
    "\n",
    "experiment_name = \"default_v3\"\n",
    "saveas = opj(\"results\", f\"{experiment_name}.csv\")\n",
    "checkpoint_save_dir = opj(\"ckpts\", experiment_name)\n",
    "exp_times = 10\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment(df_dir, df_file, N):\n",
    "    exp_name = df_file.split(\".\")[0]\n",
    "    # load data\n",
    "    data_dir = opj(df_dir, df_file)\n",
    "    chart_df = pd.read_csv(data_dir)\n",
    "    i1 = 0\n",
    "    i2 = len(chart_df)-1\n",
    "    st = \"2018-02-14 14:00:00\"\n",
    "    en = \"2022-04-15 23:00:00\"\n",
    "    filt = []\n",
    "    for index, row in chart_df.iterrows():\n",
    "        if chart_df.iloc[i1]['datetime'] < row.datetime and row.datetime < st:\n",
    "            i1 = index\n",
    "        if en < row.datetime and row.datetime < chart_df.iloc[i2]['datetime']:\n",
    "            i2 = index\n",
    "    chart_df = chart_df[i1+1:i2]\n",
    "    chart_df.index = range(len(chart_df))\n",
    "    \n",
    "    # Train High Model\n",
    "    ## train/validation/test split \n",
    "    train_size = int(chart_df.shape[0] * 0.8) \n",
    "    train_df = chart_df.iloc[:train_size,:] \n",
    "\n",
    "    val_size = int(chart_df.shape[0] * 0.1) \n",
    "    val_df = chart_df.iloc[train_size:train_size+val_size,:]  \n",
    "\n",
    "    test_df = chart_df.iloc[train_size+val_size:, :] \n",
    "    \n",
    "    categorical_columns = [\"months\", \"days\", \"hours\"]\n",
    "    features = train_df.columns\n",
    "\n",
    "    cat_idxs = [0, 1, 2] \n",
    "    cat_dims = [13, 32, 25] \n",
    "\n",
    "    tabnet_params = {\"cat_idxs\":cat_idxs, \n",
    "                     \"cat_dims\":cat_dims, \n",
    "                     \"cat_emb_dim\":1, \n",
    "                     \"optimizer_fn\":torch.optim.Adam,\n",
    "                     \"seed\": N,\n",
    "                     \"verbose\": 0\n",
    "                    } \n",
    "    \n",
    "    input_columns = [] \n",
    "    skips = ['high_delta', 'low_delta', 'years', 'datetime']\n",
    "    for col in train_df.columns:\n",
    "        if col in skips: continue\n",
    "        input_columns.append(col) \n",
    "\n",
    "    X_train = train_df[input_columns].values \n",
    "    Y_train = train_df['high_delta'].values \n",
    "    Y_train = Y_train.reshape((-1,1))\n",
    "\n",
    "    X_val = val_df[input_columns].values\n",
    "    Y_val = val_df['high_delta'].values \n",
    "    Y_val = Y_val.reshape((-1,1))\n",
    "\n",
    "    X_test = test_df[input_columns].values \n",
    "    Y_test = test_df['high_delta'].values  \n",
    "    Y_test = Y_test.reshape((-1,1))\n",
    "    \n",
    "    reg_high = TabNetRegressor(**tabnet_params) \n",
    "\n",
    "    reg_high.fit(X_train, Y_train, \n",
    "                 eval_set=[(X_val, Y_val)], \n",
    "                 max_epochs=200, \n",
    "                 patience=200)  \n",
    "    \n",
    "    Y_pred = reg_high.predict(X_test).flatten() \n",
    "    \n",
    "    exp = f\"{exp_name}-high\"\n",
    "    if exp not in results:\n",
    "        results[exp] = []\n",
    "        \n",
    "    results[exp].append(\n",
    "        {\n",
    "            \"MSE\": mean_squared_error(Y_test, Y_pred),\n",
    "            \"MAE\": mean_absolute_error(Y_test, Y_pred)\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    saveas = opj(checkpoint_save_dir, f\"{exp}-{N}\")\n",
    "    reg_high.save_model(saveas)\n",
    "    \n",
    "    # Train Low Model\n",
    "    input_columns = [] \n",
    "    skips = ['high_delta', 'low_delta', 'years', 'datetime']\n",
    "    for col in train_df.columns:\n",
    "        if col in skips: continue\n",
    "        input_columns.append(col) \n",
    "\n",
    "    X_train = train_df[input_columns].values \n",
    "    Y_train = train_df['low_delta'].values \n",
    "    Y_train = Y_train.reshape((-1,1))\n",
    "\n",
    "    X_val = val_df[input_columns].values\n",
    "    Y_val = val_df['low_delta'].values \n",
    "    Y_val = Y_val.reshape((-1,1))\n",
    "\n",
    "    X_test = test_df[input_columns].values \n",
    "    Y_test = test_df['low_delta'].values  \n",
    "    Y_test = Y_test.reshape((-1,1))\n",
    "    \n",
    "    reg_low = TabNetRegressor(**tabnet_params) \n",
    "\n",
    "    reg_low.fit(X_train, Y_train, \n",
    "                eval_set=[(X_val, Y_val)], \n",
    "                max_epochs=200, \n",
    "                patience=200)  \n",
    "    \n",
    "    Y_pred = reg_low.predict(X_test).flatten() \n",
    "    exp = f\"{exp_name}-low\"\n",
    "    if exp not in results:\n",
    "        results[exp] = []\n",
    "        \n",
    "    results[exp].append(\n",
    "        {\n",
    "            \"MSE\": mean_squared_error(Y_test, Y_pred),\n",
    "            \"MAE\": mean_absolute_error(Y_test, Y_pred)\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    saveas = opj(checkpoint_save_dir, f\"{exp}-{N}\")\n",
    "    reg_high.save_model(saveas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 200 with best_epoch = 75 and best_val_0_mse = 0.00012\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at ckpts/default_v3/default-high-0.zip\n",
      "Stop training because you reached max_epochs = 200 with best_epoch = 103 and best_val_0_mse = 0.00013\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at ckpts/default_v3/default-low-0.zip\n",
      "Stop training because you reached max_epochs = 200 with best_epoch = 102 and best_val_0_mse = 0.00012\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at ckpts/default_v3/default-high-1.zip\n",
      "Stop training because you reached max_epochs = 200 with best_epoch = 82 and best_val_0_mse = 0.00013\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at ckpts/default_v3/default-low-1.zip\n",
      "Stop training because you reached max_epochs = 200 with best_epoch = 153 and best_val_0_mse = 0.00012\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at ckpts/default_v3/default-high-2.zip\n",
      "Stop training because you reached max_epochs = 200 with best_epoch = 185 and best_val_0_mse = 0.00013\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at ckpts/default_v3/default-low-2.zip\n",
      "Stop training because you reached max_epochs = 200 with best_epoch = 101 and best_val_0_mse = 0.00012\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at ckpts/default_v3/default-high-3.zip\n",
      "Stop training because you reached max_epochs = 200 with best_epoch = 53 and best_val_0_mse = 0.00013\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at ckpts/default_v3/default-low-3.zip\n",
      "Stop training because you reached max_epochs = 200 with best_epoch = 192 and best_val_0_mse = 0.00012\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at ckpts/default_v3/default-high-4.zip\n",
      "Stop training because you reached max_epochs = 200 with best_epoch = 172 and best_val_0_mse = 0.00013\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at ckpts/default_v3/default-low-4.zip\n",
      "Stop training because you reached max_epochs = 200 with best_epoch = 179 and best_val_0_mse = 0.00012\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at ckpts/default_v3/default-high-5.zip\n",
      "Stop training because you reached max_epochs = 200 with best_epoch = 188 and best_val_0_mse = 0.00014\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at ckpts/default_v3/default-low-5.zip\n",
      "Stop training because you reached max_epochs = 200 with best_epoch = 104 and best_val_0_mse = 0.00012\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at ckpts/default_v3/default-high-6.zip\n",
      "Stop training because you reached max_epochs = 200 with best_epoch = 129 and best_val_0_mse = 0.00013\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at ckpts/default_v3/default-low-6.zip\n",
      "Stop training because you reached max_epochs = 200 with best_epoch = 59 and best_val_0_mse = 0.00012\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at ckpts/default_v3/default-high-7.zip\n",
      "Stop training because you reached max_epochs = 200 with best_epoch = 154 and best_val_0_mse = 0.00013\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at ckpts/default_v3/default-low-7.zip\n",
      "Stop training because you reached max_epochs = 200 with best_epoch = 60 and best_val_0_mse = 0.00012\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at ckpts/default_v3/default-high-8.zip\n",
      "Stop training because you reached max_epochs = 200 with best_epoch = 94 and best_val_0_mse = 0.00013\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at ckpts/default_v3/default-low-8.zip\n",
      "Stop training because you reached max_epochs = 200 with best_epoch = 196 and best_val_0_mse = 0.00012\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at ckpts/default_v3/default-high-9.zip\n",
      "Stop training because you reached max_epochs = 200 with best_epoch = 115 and best_val_0_mse = 0.00013\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at ckpts/default_v3/default-low-9.zip\n"
     ]
    }
   ],
   "source": [
    "for df_file in df_files:\n",
    "    for i in range(exp_times):\n",
    "        experiment(df_dir, df_file, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(checkpoint_save_dir):\n",
    "    os.makedirs(checkpoint_save_dir, exist_ok=True)\n",
    "with open(saveas, 'w') as f:\n",
    "    for key in results.keys():\n",
    "        f.write(\"%s, %s\\n\" % (key, results[key]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
