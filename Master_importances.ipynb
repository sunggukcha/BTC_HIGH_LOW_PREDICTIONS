{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "opj = os.path.join\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor \n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ckpts/no_neutral_8hours/bert-high-9.zip\n",
      "ckpts/no_neutral_8hours/bert-high-1.zip\n",
      "ckpts/no_neutral_8hours/bert-high-0.zip\n",
      "ckpts/no_neutral_8hours/bert-high-8.zip\n",
      "ckpts/no_neutral_8hours/bert-high-7.zip\n",
      "ckpts/no_neutral_8hours/bert-high-2.zip\n",
      "ckpts/no_neutral_8hours/bert-high-4.zip\n",
      "ckpts/no_neutral_8hours/bert-high-6.zip\n",
      "ckpts/no_neutral_8hours/bert-high-5.zip\n",
      "ckpts/no_neutral_8hours/bert-high-3.zip\n"
     ]
    }
   ],
   "source": [
    "ckpt_dir = \"ckpts/no_neutral_8hours\"\n",
    "model_name = \"bert-high\"\n",
    "ckpts = []\n",
    "for file in os.listdir(ckpt_dir):\n",
    "    if model_name in file:\n",
    "        fdir = opj(ckpt_dir, file)\n",
    "        ckpts.append(fdir)\n",
    "        print(fdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dir = \"data/8hours/bert.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getParams(df_dir, seed):\n",
    "    # load data\n",
    "    data_dir = df_dir\n",
    "    chart_df = pd.read_csv(df_dir)\n",
    "    i1 = 0\n",
    "    i2 = len(chart_df)-1\n",
    "    st = \"2018-02-14 14:00:00\"\n",
    "    en = \"2022-04-15 23:00:00\"\n",
    "    filt = []\n",
    "    for index, row in chart_df.iterrows():\n",
    "        if chart_df.iloc[i1]['datetime'] < row.datetime and row.datetime < st:\n",
    "            i1 = index\n",
    "        if en < row.datetime and row.datetime < chart_df.iloc[i2]['datetime']:\n",
    "            i2 = index\n",
    "    chart_df = chart_df[i1+1:i2]\n",
    "    chart_df.index = range(len(chart_df))\n",
    "    \n",
    "    # Train High Model\n",
    "    ## train/validation/test split \n",
    "    train_size = int(chart_df.shape[0] * 0.8) \n",
    "    train_df = chart_df.iloc[:train_size,:] \n",
    "\n",
    "    val_size = int(chart_df.shape[0] * 0.1) \n",
    "    val_df = chart_df.iloc[train_size:train_size+val_size,:]  \n",
    "\n",
    "    test_df = chart_df.iloc[train_size+val_size:, :] \n",
    "    \n",
    "    categorical_columns = [\"months\", \"days\", \"hours\"]\n",
    "    features = train_df.columns\n",
    "    \n",
    "    \n",
    "    cat_idxs = [0, 1, 2] \n",
    "    cat_dims = [13, 32, 25] \n",
    "    \n",
    "    tabnet_params = {\"cat_idxs\":cat_idxs, \n",
    "                     \"cat_dims\":cat_dims, \n",
    "                     \"cat_emb_dim\":1, \n",
    "                     \"optimizer_fn\":torch.optim.Adam,\n",
    "                     \"seed\": seed\n",
    "                    }\n",
    "    \n",
    "    input_columns = [] \n",
    "    skips = ['low_delta', 'years', 'datetime', 'sent_2']\n",
    "    for col in train_df.columns:\n",
    "        if col in skips: continue\n",
    "        input_columns.append(col) \n",
    "\n",
    "    X_train = train_df[input_columns].values \n",
    "    Y_train = train_df['high_delta'].values \n",
    "    Y_train = Y_train.reshape((-1,1))\n",
    "\n",
    "    X_val = val_df[input_columns].values\n",
    "    Y_val = val_df['high_delta'].values \n",
    "    Y_val = Y_val.reshape((-1,1))\n",
    "\n",
    "    X_test = test_df[input_columns].values \n",
    "    Y_test = test_df['high_delta'].values  \n",
    "    Y_test = Y_test.reshape((-1,1))\n",
    "    \n",
    "    return X_train, tabnet_params\n",
    "    \n",
    "def getRegressor(tabnet_params):\n",
    "    regressor = TabNetRegressor(**tabnet_params)\n",
    "    return regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getImportance(df_dir, model_dir):\n",
    "    seed = model_dir[-4]\n",
    "    X_train, params = getParams(df_dir, seed)\n",
    "    regressor = TabNetRegressor()\n",
    "    regressor.load_model(model_dir)\n",
    "    \n",
    "    print(X_train)\n",
    "    \n",
    "    #feat_importances = regressor.feature_importances_\n",
    "    feat_importances = regressor._compute_feature_importances(X_train)\n",
    "    indices = np.argsort(feat_importances)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.title(\"Feature importances\")\n",
    "    plt.barh(range(len(feat_importances)), feat_importances[indices],\n",
    "           color=\"r\", align=\"center\")\n",
    "    # If you want to define your own labels,\n",
    "    # change indices to a list of labels on the following line.\n",
    "    plt.yticks(range(len(feat_importances)), [FEATS[idx] for idx in indices])\n",
    "    plt.ylim([-1, len(feat_importances)])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ckpts/no_neutral_8hours/bert-high-9.zip\n",
      "Device used : cuda\n",
      "Device used : cuda\n",
      "[[ 2.         14.         16.         ...  1.04162152  1.34896588\n",
      "   1.03379448]\n",
      " [ 2.         14.         20.         ...  1.05858519  1.02005855\n",
      "   1.03362294]\n",
      " [ 2.         15.          0.         ...  1.03285074  0.60736389\n",
      "   1.06300886]\n",
      " ...\n",
      " [ 6.         15.         12.         ...  0.99158888  1.04669938\n",
      "   0.9944384 ]\n",
      " [ 6.         15.         16.         ...  0.98989911  2.52337654\n",
      "   0.99634937]\n",
      " [ 6.         15.         20.         ...  1.00763406  0.76513055\n",
      "   1.00004009]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ckpt \u001b[38;5;129;01min\u001b[39;00m ckpts:\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(ckpt)\n\u001b[0;32m----> 3\u001b[0m     \u001b[43mgetImportance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36mgetImportance\u001b[0;34m(df_dir, model_dir)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(X_train)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m#feat_importances = regressor.feature_importances_\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m feat_importances \u001b[38;5;241m=\u001b[39m \u001b[43mregressor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compute_feature_importances\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margsort(feat_importances)\n\u001b[1;32m     13\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pytorch_tabnet/abstract_model.py:698\u001b[0m, in \u001b[0;36mTabModel._compute_feature_importances\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m    696\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnetwork\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m    697\u001b[0m feature_importances_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnetwork\u001b[38;5;241m.\u001b[39mpost_embed_dim))\n\u001b[0;32m--> 698\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data, targets \u001b[38;5;129;01min\u001b[39;00m loader:\n\u001b[1;32m    699\u001b[0m     data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m    700\u001b[0m     M_explain, masks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnetwork\u001b[38;5;241m.\u001b[39mforward_masks(data)\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "for ckpt in ckpts:\n",
    "    print(ckpt)\n",
    "    getImportance(df_dir, ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
